{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2 - 분산처리시스템 구성요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 분산처리 시스템이 갖춰야 할 필수 항목"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산 처리 시스템 : 문제점\n",
    "\n",
    "- 분산 처리 시스템의 문제점\n",
    "    * ** 복잡한 프로그래밍(기존 MPI 방법) **\n",
    "    * 데이터와 프로세스의 ** sync ** 유지\n",
    "    \n",
    "    \n",
    "- Partial failures : 수많은 컴퓨터를 사용하는 경우에 일부의 컴퓨터가 고장나는 경우\n",
    "    * ** 시스템은 반드시 partial failure에 대처가 요구됨 **\n",
    "    * 컴포넌트의 failure(전치 시스템의 failure가 아닌)는 애플리케이션 성능 저하를 유발함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 Recoverability\n",
    "\n",
    "- 시스템의 컴포넌트가 fail 하더라도 시스템을 통해 작업은 지속적으로 수행되어야 함\n",
    "    * ** failure **로 인해 ** 어떠한 데이터의 손실도 발생하면 안됨 **\n",
    "        * 구글이 생각한 방법 copy 3개 만듦, 그리고 복구가 가능하게 만듦(google file system에서 제시)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컴포넌트 Recovery\n",
    "\n",
    "- 시스템의 컴포넌트가 fail되고 다시 recover된 경우, 시스템에 rejoin하는 것이 가능해야함\n",
    "    * ** 전체 시스템의 재 시작 없이 수행 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalability\n",
    "\n",
    "- 데이터의 양이 증가하면, 각 작업의 성능이 감소함\n",
    "    * 시스템은 fail되지 않음\n",
    "    \n",
    "    \n",
    "- 시스템의 resource를 증가시키면, 비례적으로 로드 capacity가 증가함\n",
    "    * 데이터가 추가 됐을 때 컴퓨터 대수만 증가시키면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하둡에서의 필수 항목 구현내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop의 역사\n",
    "\n",
    "- Hadoop은 1990년-2000년 사이의 Google의 연구로 부터 시작\n",
    "    * Google File System(GFS) in 2003\n",
    "    * MapReduce in 2004\n",
    "    \n",
    "    \n",
    "- 기본 분산 컴퓨팅의 문제점을 해결할 수 있는 새로운 접근법\n",
    "    * ** _Reliability_ ** 와  ** _Scalability_ ** 문제를 모두 해결\n",
    "    \n",
    "    \n",
    "- Core concept : 초기 데이터를 시스템에 분산하여 저장\n",
    "    * 클러스터의 각 노드가 로컬 데이터에 대한 작업을 처리\n",
    "        * **initial processing을 위해 네트워크를 통해 데이터가 전송되지 않음 **\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Hadoop Concepts\n",
    "\n",
    "- 애플리케이션을 High-level 코드로 작성(java, SQL)\n",
    "    * 개발자에게 네트워크 프로그래밍, 의존성, low-level 인프라 구조에 대한 고려가 요구되지 않음\n",
    "    \n",
    "    \n",
    "- 각 노드들은 가급적 최소한의 데이터를 주고 받음\n",
    "    * 개발자는 노드들 사이의 통신에 대한 코드 작성이 필요없음\n",
    "    * 'Shared nothing' architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop : Very High-Level Overview\n",
    "\n",
    "- 시스템이 데이터를 로드할 때 'block'으로 나누어짐\n",
    "    * 기본적으로 64MB 또는 128MB 크기를 사용\n",
    "\n",
    "\n",
    "- Map tasks(MapReduce 시스템의 첫 번째 파트)는 single block 단위의 작업을 처리\n",
    "\n",
    "\n",
    "- 마스터 프로그램은 분산되어 저장된 데이터의 block에 대한 Map task 작업을 각 노드에 할당\n",
    "    * 전체 데이터 셋 중 각 노드에 저장된 데이터를 이용해 병렬적으로 작업을 수행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault Tolerance\n",
    "\n",
    "- Node가 fail한 경우, master node는 failure를 감지하고 작업을 다른 node에 할당\n",
    "\n",
    "\n",
    "- Task를 재시작 하는 것은 다른 부분에 대한 작업을 수행중인 다른 노드와의 통신을 필요로 하지 않음\n",
    "\n",
    "\n",
    "- Fail된 node를 재 시작 하는 경우, 자동적으로 시스템에 연결되어 새로운 task를 할당함\n",
    "\n",
    "\n",
    "- 특정 Node의 성능이 매우 낮은 것으로 감지되면, master node는 같은 task를 다른 node에 할당\n",
    "    * Speculative Execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
